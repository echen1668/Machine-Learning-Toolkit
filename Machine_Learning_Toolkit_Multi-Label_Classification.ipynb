{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afc5b68",
   "metadata": {},
   "source": [
    "# Machine Learning Toolkit (Multi-Label Classification)\n",
    "## This program provides a tool used to do create a machine learning model on a given dataset.\n",
    "\n",
    "## This one works with multi-label problems.\n",
    "\n",
    "Take a dataset from Kaggle or from your own and upload it to this program: https://www.kaggle.com/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245b7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as scikit_learn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import joblib as joblib\n",
    "from joblib import dump, load\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "np.random.seed(1000)\n",
    "rstate = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42dcc7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.geometry(\"600x10000\")\n",
    "root.config(bg=\"lightgrey\")\n",
    "  \n",
    "w = Label(root, text ='ML Options (Close when finished)', font = \"30\") \n",
    "w.pack()\n",
    "  \n",
    "Checkbutton1 = IntVar(value=1)  \n",
    "Checkbutton2 = IntVar(value=1)  \n",
    "Checkbutton3 = IntVar(value=1)\n",
    "Checkbutton4 = IntVar(value=0)\n",
    "Checkbutton5 = IntVar(value=0)\n",
    "Checkbutton6 = IntVar(value=0)\n",
    "Checkbutton7 = IntVar(value=0)\n",
    "Checkbutton8 = IntVar(value=0)\n",
    "  \n",
    "Button1 = Checkbutton(root, text = \"oneHotEncode\", \n",
    "                      variable = Checkbutton1,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "  \n",
    "Button2 = Checkbutton(root, text = \"Impute\",\n",
    "                      variable = Checkbutton2,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "  \n",
    "Button3 = Checkbutton(root, text = \"cutMissingRows\",\n",
    "                      variable = Checkbutton3,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)  \n",
    "Button4 = Checkbutton(root, text = \"removeOutliars\",\n",
    "                      variable = Checkbutton4,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)  \n",
    "\n",
    "Button5 = Checkbutton(root, text = \"Scaling\",\n",
    "                      variable = Checkbutton5,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)  \n",
    "\n",
    "Button6 = Checkbutton(root, text = \"QuantileTr.\",\n",
    "                      variable = Checkbutton6,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)  \n",
    "\n",
    "Button7 = Checkbutton(root, text = \"Normalize\",\n",
    "                      variable = Checkbutton7,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)  \n",
    "\n",
    "Button7 = Checkbutton(root, text = \"Normalize\",\n",
    "                      variable = Checkbutton7,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10) \n",
    "\n",
    "Button8 = Checkbutton(root, text = \"Rebalance\",\n",
    "                      variable = Checkbutton8,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10) \n",
    "    \n",
    "\n",
    "# File Name label and entry widgets\n",
    "Label(root, text=\"File Name (Do not inlcude .csv or other tags)\", bg=\"lightgrey\").pack()\n",
    "Label(root, text=\"Be aware that some datasets may not work well with certian models\", bg=\"lightgrey\").pack()\n",
    "filename = Entry(root, bd=2)\n",
    "filename.insert(0, \"train\")\n",
    "filename.pack()\n",
    "\n",
    "# File Type and dropdown widgets\n",
    "file_type = StringVar(root)\n",
    "file_type.set(\"Select a File Type\")\n",
    "filetype_menu = OptionMenu(root, file_type,'csv','excel')\n",
    "filetype_menu.pack()\n",
    "   \n",
    "Button1.pack() # OneHotEncode\n",
    "\n",
    "Button2.pack() # Impute \n",
    "\n",
    "Button3.pack() # cut Missing Rows\n",
    "\n",
    "Button4.pack() # remove Outlairs\n",
    "\n",
    "Label(root, text=\"(Only if you chose remove outliers)\", bg=\"lightgrey\").pack()\n",
    "Label(root, text=\"Remove Outliars Threshold\", bg=\"lightgrey\").pack()\n",
    "Threshold = Entry(root, bd=2)\n",
    "Threshold.insert(0, \"0\")\n",
    "Threshold.pack()\n",
    "#threshold = Threshold.get()\n",
    "\n",
    "# Note at some Scaling Methods may not work with some models\n",
    "Label(root, text=\"Note at some Scaling Methods may not be compatible with some models\", bg=\"lightgrey\").pack()\n",
    "Button5.pack() # Scaling\n",
    "\n",
    "# Scaling Type and dropdown widgets\n",
    "Label(root, text=\"(Only if you chose Scaling)\", bg=\"lightgrey\").pack()\n",
    "scale_type = StringVar(root)\n",
    "scale_type.set(\"Select a Scaling Type\")\n",
    "scale_type_menu = OptionMenu(root, scale_type,'MinMaxScaler','RobustScaler','MaxAbsScaler','StandardScaler')\n",
    "scale_type_menu.pack()\n",
    "\n",
    "Button6.pack() # Quantile\n",
    "\n",
    "Button7.pack() # Normalize\n",
    "\n",
    "Button8.pack() # Rebalance\n",
    "\n",
    "\n",
    "# Rebalance Type and dropdown widgets\n",
    "Label(root, text=\"(Only if you chose Rebalance)\", bg=\"lightgrey\").pack()\n",
    "reblance_type = StringVar(root)\n",
    "reblance_type.set(\"Select a Rebalance Type\")\n",
    "reblance_type_menu = OptionMenu(root, reblance_type,'RandomUnderSampler','RandomOverSampler','SMOTE','ADASYN')\n",
    "reblance_type_menu.pack()\n",
    "\n",
    "def getInput():\n",
    "    \n",
    "    global file_name\n",
    "    file_name = filename.get()\n",
    "    global filetype\n",
    "    filetype = file_type.get()\n",
    "    global OneHotEncode\n",
    "    OneHotEncode = Checkbutton1.get()\n",
    "    global Impute\n",
    "    Impute = Checkbutton2.get()\n",
    "    global cutMissingRows\n",
    "    cutMissingRows = Checkbutton3.get()\n",
    "    global removeOutlairs\n",
    "    removeOutlairs = Checkbutton4.get()\n",
    "    global threshold\n",
    "    threshold = Threshold.get()\n",
    "    global Scaling\n",
    "    Scaling = Checkbutton5.get()\n",
    "    global scaletype\n",
    "    scaletype = scale_type.get()\n",
    "    global Quantile\n",
    "    Quantile = Checkbutton6.get()\n",
    "    global Normalize\n",
    "    Normalize = Checkbutton7.get()\n",
    "    global Rebalance\n",
    "    Rebalance = Checkbutton8.get()\n",
    "    global reblancetype\n",
    "    reblancetype = reblance_type.get()\n",
    "    root.destroy()\n",
    "    \n",
    "#Sumbit values\n",
    "Button(root, text = \"submit\",\n",
    "           command = getInput).pack() \n",
    "\n",
    "mainloop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f00a02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast-cancer\n",
      "csv\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "MinMaxScaler\n",
      "0\n",
      "0\n",
      "0\n",
      "Select a Rebalance Type\n"
     ]
    }
   ],
   "source": [
    "print(file_name)\n",
    "print(filetype)\n",
    "print(OneHotEncode)\n",
    "print(Impute)\n",
    "print(cutMissingRows)\n",
    "print(removeOutlairs)\n",
    "print(threshold)\n",
    "print(Scaling)\n",
    "print(scaletype)\n",
    "print(Quantile)\n",
    "print(Normalize)\n",
    "print(Rebalance)\n",
    "print(reblancetype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e80ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.geometry(\"600x800\")\n",
    "root.config(bg=\"lightgrey\")\n",
    "  \n",
    "x = Label(root, text ='ML Options 2 (Close when finished)', font = \"30\") \n",
    "x.pack()\n",
    "\n",
    "Checkbutton9 = IntVar(value=0)\n",
    "\n",
    "Button9 = Checkbutton(root, text = \"FeatureSelection\",\n",
    "                      variable = Checkbutton9,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10) \n",
    "\n",
    "Button9.pack() # FeatureSelection\n",
    "\n",
    "# Feature Selection Type and dropdown widgets\n",
    "Label(root, text=\"(Only if you chose FeatureSelection)\", bg=\"lightgrey\").pack()\n",
    "featureselection_type = StringVar(root)\n",
    "featureselection_type.set(\"Select a Feature Selection Type\")\n",
    "featureselection_type_menu = OptionMenu(root, featureselection_type,'MRMR','SelectKBest','SelectPercentile','VarianceThreshold')\n",
    "featureselection_type_menu.pack()\n",
    "\n",
    "# Feature Selection Type 2 and dropdown widgets\n",
    "Label(root, text=\"(Only if you chose SelectKBest or SelectPercentile)\", bg=\"lightgrey\").pack()\n",
    "featureselection_type2 = StringVar(root)\n",
    "featureselection_type2.set(\"Select a 2nd Feature Selection Type\")\n",
    "featureselection_type2_menu = OptionMenu(root, featureselection_type2,'f_classif','chi2')\n",
    "featureselection_type2_menu.pack()\n",
    "\n",
    "# N_features label and entry widgets\n",
    "Label(root, text=\"# of features (Oly if you chose FeatureSelection)\", bg=\"lightgrey\").pack()\n",
    "features = Entry(root, bd=2)\n",
    "features.insert(0, \"20\")\n",
    "features.pack()\n",
    "\n",
    "# Hyper. Tune Strategy and dropdown widgets\n",
    "strategy_type = StringVar(root)\n",
    "strategy_type.set(\"Select a Hyper. Tune Strategy\")\n",
    "strategy_type_menu = OptionMenu(root, strategy_type,'random','bayesian','grid')\n",
    "strategy_type_menu.pack()\n",
    "\n",
    "# Hyper. Tune Num. Itr label and entry widgets\n",
    "Label(root, text=\"Hyper. Tune # of Itr\", bg=\"lightgrey\").pack()\n",
    "itr = Entry(root, bd=2)\n",
    "itr.insert(0, \"20\")\n",
    "itr.pack() \n",
    "#n_itr = itr.get()\n",
    "\n",
    "# first feature label and entry widgets\n",
    "Label(root, text=\"First feature name.\", bg=\"lightgrey\").pack()\n",
    "firstFeature = Entry(root, bd=2)\n",
    "firstFeature.pack() \n",
    "\n",
    "# last feature label and entry widgets\n",
    "Label(root, text=\"Last feature name.\", bg=\"lightgrey\").pack()\n",
    "lastFeature = Entry(root, bd=2)\n",
    "lastFeature.pack() \n",
    "\n",
    "# Final Label label and entry widgets\n",
    "Label(root, text=\"Label Name.\", bg=\"lightgrey\").pack()\n",
    "final_label = Entry(root, bd=2)\n",
    "final_label.pack() \n",
    "\n",
    "def getInput():\n",
    "    \n",
    "    global strategytype\n",
    "    strategytype = strategy_type.get()\n",
    "    global n_itr\n",
    "    n_itr = itr.get()\n",
    "    global first_Feature\n",
    "    first_Feature = firstFeature.get()\n",
    "    global last_Feature\n",
    "    last_Feature = lastFeature.get()\n",
    "    global output_label\n",
    "    output_label = final_label.get()\n",
    "    global FeatureSelection\n",
    "    FeatureSelection = Checkbutton9.get()\n",
    "    global featureselectiontype\n",
    "    featureselectiontype = featureselection_type.get()\n",
    "    global featureselectiontype2\n",
    "    featureselectiontype2 = featureselection_type2.get()\n",
    "    global n_features\n",
    "    n_features = features.get()\n",
    "    root.destroy()\n",
    "    \n",
    "#Sumbit values\n",
    "Button(root, text = \"submit\",\n",
    "           command = getInput).pack() \n",
    "  \n",
    "mainloop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ad98d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\n",
      "20\n",
      "radius_mean\n",
      "fractal_dimension_worst\n",
      "diagnosis\n",
      "1\n",
      "MRMR\n",
      "f_classif\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(strategytype)\n",
    "print(n_itr)\n",
    "print(first_Feature)\n",
    "print(last_Feature)\n",
    "print(output_label)\n",
    "print(FeatureSelection)\n",
    "print(featureselectiontype)\n",
    "print(featureselectiontype2)\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91321283",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.geometry(\"600x500\")\n",
    "root.config(bg=\"lightgrey\")\n",
    "  \n",
    "y = Label(root, text ='ML Algorithims to Use (Must have at least 1)', font = \"30\") \n",
    "y.pack()\n",
    " \n",
    "Checkbutton11 = IntVar(value=1)\n",
    "Checkbutton12 = IntVar(value=0)\n",
    "Checkbutton13 = IntVar(value=0)\n",
    "Checkbutton14 = IntVar(value=0)\n",
    "Checkbutton15 = IntVar(value=0)\n",
    "Checkbutton16 = IntVar(value=0)\n",
    "Checkbutton17 = IntVar(value=0)\n",
    "Checkbutton18 = IntVar(value=0)\n",
    "Checkbutton19 = IntVar(value=0)\n",
    "Checkbutton20 = IntVar(value=0)\n",
    "Checkbutton21 = IntVar(value=0)\n",
    "  \n",
    "Button11 = Checkbutton(root, text = \"Random Forest\", \n",
    "                      variable = Checkbutton11,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button12 = Checkbutton(root, text = \"CategoricalNB\", \n",
    "                      variable = Checkbutton12,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button13 = Checkbutton(root, text = \"AdaBoost\", \n",
    "                      variable = Checkbutton13,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button14 = Checkbutton(root, text = \"SGD Elastic\", \n",
    "                      variable = Checkbutton14,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button15 = Checkbutton(root, text = \"SGD L2\", \n",
    "                      variable = Checkbutton15,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button16 = Checkbutton(root, text = \"Logistic Reg. L2\", \n",
    "                      variable = Checkbutton16,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button17 = Checkbutton(root, text = \"Logistic Reg.\", \n",
    "                      variable = Checkbutton17,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button18 = Checkbutton(root, text = \"Descision Tree\", \n",
    "                      variable = Checkbutton18,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button19 = Checkbutton(root, text = \"GaussianNB\", \n",
    "                      variable = Checkbutton19,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button20 = Checkbutton(root, text = \"SVM\", \n",
    "                      variable = Checkbutton20,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "Button21 = Checkbutton(root, text = \"KNearest N.\", \n",
    "                      variable = Checkbutton21,\n",
    "                      onvalue = 1,\n",
    "                      offvalue = 0,\n",
    "                      height = 2,\n",
    "                      width = 10)\n",
    "\n",
    "\n",
    "Button11.pack() # rf\n",
    "Button12.pack() # CategoricalNB\n",
    "Button13.pack() # AdaBoost\n",
    "Button14.pack() # sgd_elastic\n",
    "Button15.pack() # sgd_l2\n",
    "Button16.pack() # lr_l2\n",
    "Button17.pack() # lr\n",
    "Button18.pack() # dt\n",
    "Button19.pack() # GaussianNB\n",
    "Button20.pack() # svm\n",
    "Button21.pack() # knn\n",
    "\n",
    "\n",
    "def getInput():\n",
    "    \n",
    "    global algorithms\n",
    "    algorithms = []\n",
    "    \n",
    "    rf = Checkbutton11.get()\n",
    "    if rf == 1:\n",
    "        algorithms.append(\"rf\")\n",
    "    CategoricalNB = Checkbutton12.get()\n",
    "    if CategoricalNB == 1:\n",
    "        algorithms.append(\"CategoricalNB\")\n",
    "    AdaBoost = Checkbutton13.get()\n",
    "    if AdaBoost == 1:\n",
    "        algorithms.append(\"AdaBoost\")\n",
    "    sgd_elastic = Checkbutton14.get()\n",
    "    if sgd_elastic == 1:\n",
    "        algorithms.append(\"sgd_elastic\")\n",
    "    sgd_l2 = Checkbutton15.get()\n",
    "    if sgd_l2 == 1:\n",
    "        algorithms.append(\"sgd_l2\")\n",
    "    lr_l2 = Checkbutton16.get()\n",
    "    if lr_l2 == 1:\n",
    "        algorithms.append(\"lr_l2\")\n",
    "    lr = Checkbutton17.get()\n",
    "    if lr == 1:\n",
    "        algorithms.append(\"lr\")\n",
    "    dt = Checkbutton18.get()\n",
    "    if dt == 1:\n",
    "        algorithms.append(\"dt\")\n",
    "    GaussianNB = Checkbutton19.get()\n",
    "    if GaussianNB == 1:\n",
    "        algorithms.append(\"GaussianNB\")\n",
    "    svm = Checkbutton20.get()\n",
    "    if svm == 1:\n",
    "        algorithms.append(\"svm\")\n",
    "    knn = Checkbutton21.get()\n",
    "    if knn == 1:\n",
    "        algorithms.append(\"knn\")\n",
    "    \n",
    "    root.destroy()\n",
    "    \n",
    "#Sumbit values\n",
    "Button(root, text = \"submit\",\n",
    "           command = getInput).pack() \n",
    "  \n",
    "mainloop() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20bb61fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rf', 'AdaBoost', 'sgd_elastic', 'sgd_l2', 'lr_l2', 'lr', 'dt', 'GaussianNB', 'svm', 'knn']\n"
     ]
    }
   ],
   "source": [
    "print(algorithms)\n",
    "\n",
    "options = {\n",
    "    'oneHotEncode' : True if OneHotEncode == 1 else False, \n",
    "    'Impute': True if Impute == 1 else False, \n",
    "    'cutMissingRows' : True if cutMissingRows == 1 else False,\n",
    "    'removeBig': True if removeOutlairs == 1 else False, \n",
    "    'removeBig_N': int(threshold), \n",
    "    'Scaling': True if Scaling == 1 else False, \n",
    "    'scalingMethod': scaletype, \n",
    "    'QuantileTransformer':True if Quantile == 1 else False, \n",
    "    'Normalize':True if Normalize == 1 else False,\n",
    "    'rebalance' : True if Rebalance == 1 else False,\n",
    "    'rebalance_type':reblancetype,\n",
    "    'FeatureSelection': True if FeatureSelection == 1 else False,\n",
    "    'method': featureselectiontype, \n",
    "    \"type\": featureselectiontype2, \n",
    "    'N_features': int(n_features), \n",
    "    'per':10,\n",
    "    'strategy': strategytype, \n",
    "    'itr': int(n_itr)\n",
    "}\n",
    "\n",
    "with open(\"parameter_setup.txt\", 'w') as f: \n",
    "    f.write('Data Set Name: %s\\n' % file_name)\n",
    "    f.write('ML Alogorithims: %s\\n' % algorithms)\n",
    "    for key, value in options.items(): \n",
    "        f.write('%s:%s\\n' % (key, value))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5949654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mrmr_selection in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (0.2.8)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: joblib in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from mrmr_selection) (3.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from mrmr_selection) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.0.3 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.10.0)\n",
      "Requirement already satisfied: category-encoders in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from mrmr_selection) (2.6.1)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.23.5)\n",
      "Requirement already satisfied: polars>=0.12.5 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from mrmr_selection) (0.18.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->mrmr_selection) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->mrmr_selection) (2.8.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from category-encoders->mrmr_selection) (0.5.3)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from category-encoders->mrmr_selection) (0.13.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from scikit-learn->mrmr_selection) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from jinja2->mrmr_selection) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from tqdm->mrmr_selection) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category-encoders->mrmr_selection) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category-encoders->mrmr_selection) (22.0)\n"
     ]
    }
   ],
   "source": [
    "pip install mrmr_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba38eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrmr\n",
    "from mrmr import mrmr_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987cce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.2.2)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from scikit-optimize) (23.7.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.23.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.1.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.10.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alanhome\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f6a2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60fde0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = file_name\n",
    "\n",
    "if filetype == 'csv':\n",
    "    #filename = filename + \".csv\"\n",
    "    raw_df = pd.read_csv(filename + \".csv\" )\n",
    "elif filetype == 'excel':\n",
    "    #filename = filename + \".xlsx\"\n",
    "    raw_df = pd.read_excel(filename + \".xlsx\")\n",
    "else:\n",
    "    #filename = filename + \".csv\"\n",
    "    raw_df = pd.read_csv(filename + \".csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "debcdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab0e74b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "7  84458202         M        13.71         20.83           90.20      577.9   \n",
       "8    844981         M        13.00         21.82           87.50      519.8   \n",
       "9  84501001         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "5  ...         15.47          23.75           103.40       741.6   \n",
       "6  ...         22.88          27.66           153.20      1606.0   \n",
       "7  ...         17.06          28.14           110.60       897.0   \n",
       "8  ...         15.49          30.73           106.20       739.3   \n",
       "9  ...         15.09          40.68            97.65       711.4   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "5            0.1791             0.5249           0.5355                0.1741   \n",
       "6            0.1442             0.2576           0.3784                0.1932   \n",
       "7            0.1654             0.3682           0.2678                0.1556   \n",
       "8            0.1703             0.5401           0.5390                0.2060   \n",
       "9            0.1853             1.0580           1.1050                0.2210   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "5          0.3985                  0.12440  \n",
       "6          0.3063                  0.08368  \n",
       "7          0.3196                  0.11510  \n",
       "8          0.4378                  0.10720  \n",
       "9          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d19e60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, we should cut rows that have missing series of values (cutMissing), impute the data (Impute), and remove very large data values (removeBig)\n",
    "def preprocess(df, input_cols, label_cols, numeric_cols, categorical_cols, Impute=True, cutMissingRows=True, oneHotEncode=True, removeBig=False, N=20000, Scaling=False, scalingMethod='MinMaxScaler', QuantileTransformer=False, Normalize=False):\n",
    "    if oneHotEncode == True:\n",
    "        print(\"oneHotEncode\")\n",
    "        # One Hot Encode catagorical variables\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        encoder.fit(raw_df[categorical_cols])\n",
    "        encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "        df[encoded_cols] = encoder.transform(df[categorical_cols])\n",
    "        input_cols = numeric_cols + encoded_cols\n",
    "    \n",
    "    if Impute == True:\n",
    "        print(\"Impute\")\n",
    "        # Impute the remaining missing numeric data\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        imputer = SimpleImputer(strategy = 'mean')\n",
    "        imputer.fit(df[numeric_cols])\n",
    "        df[numeric_cols] = imputer.transform(df[numeric_cols])\n",
    "        \n",
    "    if cutMissingRows == True:\n",
    "        print(\"cutMissingRows\")\n",
    "        # Drop rows with missing values\n",
    "        df = df.dropna()\n",
    "    \n",
    "    if removeBig == True:\n",
    "        print(\"removeBig\")\n",
    "        # Remove rows that have a value greater than N for any column. Default N is 20000\n",
    "        for column  in df[numeric_cols]:\n",
    "            df = df.drop(df.index[df[column] > N])\n",
    "    \n",
    "    if Scaling == True:\n",
    "        print(\"Scaling\")\n",
    "        # Scaling the input features for a chosen method. Default is MinMaxScaler.\n",
    "        if scalingMethod == 'MinMaxScaler': \n",
    "            print(\"MinMaxScaler\")\n",
    "            # This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.\n",
    "            from sklearn.preprocessing import MinMaxScaler\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scalingMethod == 'RobustScaler':\n",
    "            print(\"RobustScaler\")\n",
    "            # This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).\n",
    "            from sklearn.preprocessing import RobustScaler\n",
    "            scaler = RobustScaler()\n",
    "        elif scalingMethod == 'MaxAbsScaler':\n",
    "            print(\"MaxAbsScaler\")\n",
    "            # Scale each feature by its maximum absolute value.\n",
    "            from sklearn.preprocessing import MaxAbsScaler\n",
    "            scaler = MaxAbsScaler()\n",
    "        elif scalingMethod == 'StandardScaler':\n",
    "            print(\"StandardScaler\")\n",
    "            # Standardize features by removing the mean and scaling to unit variance.\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "        scaler.fit(df[numeric_cols])\n",
    "        df[numeric_cols] = scaler.transform(df[numeric_cols])\n",
    "        \n",
    "    if QuantileTransformer == True:  \n",
    "        print(\"QuantileTransformer\")\n",
    "        # transforms the features to follow a uniform or a normal distribution.\n",
    "        from sklearn.preprocessing import QuantileTransformer\n",
    "        qt = QuantileTransformer(output_distribution='normal').fit(df[numeric_cols])\n",
    "        df[numeric_cols] = qt.transform(df[numeric_cols])\n",
    "        \n",
    "    if Normalize == True:  \n",
    "        print(\"Normalize\")\n",
    "        # Normalize the data\n",
    "        from sklearn.preprocessing import Normalizer\n",
    "        normalizer = Normalizer().fit(df[numeric_cols])\n",
    "        df[numeric_cols] = normalizer.transform(df[numeric_cols])\n",
    "        \n",
    "    \n",
    "    return df, input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c883700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into input and output sets\n",
    "def split(df, input_cols, label_cols):\n",
    "    input_df = df[input_cols].copy()\n",
    "    output_df = df[label_cols].copy()\n",
    "    \n",
    "    return input_df, output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f2f9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rebalance the imbalanced data with a chosen label\n",
    "def rebalance(input_df, label_df, type='RandomUnderSampler'):\n",
    "    if type == 'RandomUnderSampler':\n",
    "        # random undersampling reduces the number of majority class randomly down to the desired ratio against the minority class.\n",
    "        from imblearn.under_sampling import RandomUnderSampler\n",
    "        rebalance = RandomUnderSampler()\n",
    "        input_df2, label_df2 = rebalance.fit_resample(input_df, label_df)\n",
    "    elif type == 'RandomOverSampler':\n",
    "        # Naive random over-sampling.\n",
    "        from imblearn.over_sampling import RandomOverSampler\n",
    "        rebalance = RandomOverSampler()\n",
    "        input_df2, label_df2 = rebalance.fit_resample(input_df, label_df)\n",
    "    elif type == 'SMOTE':\n",
    "        # SMOTE is a technique to up-sample the minority classes while avoiding overfitting.\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        rebalance = SMOTE()\n",
    "        input_df2, label_df2 = rebalance.fit_resample(input_df, label_df)    \n",
    "    elif type == 'ADASYN':\n",
    "        # Adaptive Synthetic (ADASYN) algorithm. This method is similar to SMOTE but it generates different number of samples depending on an estimate of the local distribution of the class to be oversampled.\n",
    "        from imblearn.over_sampling import ADASYN\n",
    "        rebalance = ADASYN()\n",
    "        input_df2, label_df2 = rebalance.fit_resample(input_df, label_df)                   \n",
    "    else:\n",
    "        print(\"Cannot do\")\n",
    "        input_df2, label_df2 = input_df, label_df\n",
    "        \n",
    "    return input_df2, label_df2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68837aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(input_df, output_df, method=\"MRMR\", type='f_classif', N=20, per=10):\n",
    "    if method==\"MRMR\":\n",
    "        selected_features = mrmr_classif(X=input_df, y=output_df, K=N)\n",
    "        input_df_new = input_df[selected_features]\n",
    "    elif method==\"SelectKBest\":\n",
    "        if type=='f_classif':\n",
    "            best_features =  SelectKBest(f_classif, k=N)\n",
    "            best_features.fit(input_df, output_df)\n",
    "        elif type=='chi2':\n",
    "            best_features =  SelectKBest(chi2, k=N)\n",
    "            best_features.fit(input_df, output_df)\n",
    "        # Get columns to keep and create new dataframe with those only\n",
    "        cols_idxs = best_features.get_support(indices=True)\n",
    "        input_df_new = input_df.iloc[:,cols_idxs]\n",
    "    elif method==\"SelectPercentile\": # Select features according to a percentile of the highest scores.\n",
    "        if type=='f_classif':\n",
    "            best_features =  SelectPercentile(f_classif, percentile=per)\n",
    "            best_features.fit(input_df, output_df)\n",
    "        elif type=='chi2':\n",
    "            best_features =  SelectPercentile(chi2, percentile=per)\n",
    "            best_features.fit(input_df, output_df)\n",
    "        # Get columns to keep and create new dataframe with those only\n",
    "        cols_idxs = best_features.get_support(indices=True)\n",
    "        input_df_new = input_df.iloc[:,cols_idxs]\n",
    "    elif method==\"VarianceThreshold\": # Feature selector that removes all low-variance features.\n",
    "        best_features = VarianceThreshold()\n",
    "        best_features.fit(input_df)\n",
    "        cols_idxs = best_features.get_support(indices=True)\n",
    "        input_df_new = input_df.iloc[:,cols_idxs]\n",
    "    \n",
    "    return input_df_new, list(input_df_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "510b5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model to use and its set of parameters\n",
    "def get_classifier(alg):\n",
    "    est_rs = 1000\n",
    "    if alg == 'rf':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        estimator = RandomForestClassifier(random_state=est_rs)\n",
    "        param_vals = {'max_depth': [10, 20, 30, 50, 100, 150, 200], 'n_estimators': [20, 30, 50, 70, 100, 120], 'max_leaf_nodes': [10, 20, 30, 40],\n",
    "                      'max_samples': [0.75, 0.80, 0.85, 0.90, 0.95]}\n",
    "    elif alg == 'dt':\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        estimator = DecisionTreeClassifier()\n",
    "        param_vals = {'max_depth': [2, 3, 4, 5, 8], 'min_samples_split': [2, 3, 4, 5, 7, 10], 'max_leaf_nodes': [10, 20, 30, 40],\n",
    "                      'random_state': [0, 1, 5, 10,50,100]}\n",
    "    elif alg == 'CategoricalNB':\n",
    "        from sklearn.naive_bayes import CategoricalNB # Naive Bayes\n",
    "        estimator = CategoricalNB()\n",
    "        param_vals = {'min_categories': [None]}\n",
    "    elif alg == 'GaussianNB':\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        estimator = GaussianNB()\n",
    "        param_vals = {'var_smoothing': [1e-9, 2e-9, 3e-9]}\n",
    "    elif alg == 'sgd_elastic':\n",
    "        from sklearn.linear_model import SGDClassifier # stochastic gradient descent (SGD)\n",
    "        estimator = SGDClassifier(loss='log', penalty='elasticnet')\n",
    "        param_vals = {'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1], 'l1_ratio': [0, 0.1, 0.15, 0.25, 0.4, 0.5, 0.6, .75, 0.9, 1]}\n",
    "    elif alg == 'sgd_l2':\n",
    "        from sklearn.linear_model import SGDClassifier\n",
    "        estimator = SGDClassifier(loss='log', penalty='l2')\n",
    "        param_vals = {'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1], 'l1_ratio': [0, 0.1, 0.15, 0.25, 0.4, 0.5, 0.6, .75, 0.9, 1]}\n",
    "    elif alg == 'lr_l2': # Logistic Regression\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        estimator = LogisticRegression(penalty='l2')\n",
    "        param_vals = {'random_state': [0, 1, 5, 10,50,100], 'l1_ratio': [0, 0.1, 0.15, 0.25, 0.4, 0.5, 0.6, .75, 0.9, 1]}\n",
    "    elif alg == 'lr':\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        estimator = LogisticRegression()\n",
    "        param_vals = {'random_state': [0, 1, 5, 10,50,100], 'l1_ratio': [0, 0.1, 0.15, 0.25, 0.4, 0.5, 0.6, .75, 0.9, 1]}\n",
    "    elif alg == 'AdaBoost':\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        estimator = AdaBoostClassifier()\n",
    "        param_vals = {'n_estimators': [50, 80, 90, 100, 120], \n",
    "                      'learning_rate': [0.00001, 0.0001, 0.001, 0.01]}       \n",
    "    elif alg == 'svm':\n",
    "        from sklearn import svm\n",
    "        estimator = svm.SVC(probability=True)\n",
    "        param_vals = {'C': [0.5, 1, 1.5, 2, 2.5, 3], 'degree': [2, 3, 4, 5]}            \n",
    "    elif alg == 'knn': # k-nearest neighbors\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        estimator = KNeighborsClassifier()\n",
    "        param_vals = {'n_neighbors': [5, 10, 15, 20, 25, 30], 'leaf_size': [20, 30, 40, 50]}  \n",
    "        \n",
    "    return estimator, param_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18fead5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune(estimator, param_vals, X_train, y_train, strategy='random', itr=20):\n",
    "    if strategy == 'random':\n",
    "        random_df = RandomizedSearchCV(estimator, param_distributions=param_vals,\n",
    "                              n_iter=itr, random_state=256, n_jobs=-1)\n",
    "        random_df.fit(X_train, y_train)\n",
    "        best_model = random_df.best_estimator_\n",
    "\n",
    "    elif strategy == 'bayesian':\n",
    "        bayes_df = BayesSearchCV(estimator, param_vals,\n",
    "                              n_iter=itr, random_state=256, n_jobs=-1)\n",
    "        bayes_df.fit(X_train, y_train)\n",
    "        best_model = bayes_df.best_estimator_\n",
    "    elif strategy == 'grid':\n",
    "        grid_df = GridSearchCV(estimator, param_vals, n_jobs=-1, return_train_score=True)\n",
    "        grid_df.fit(X_train, y_train)\n",
    "        best_model = grid_df.best_estimator_ \n",
    "    else:\n",
    "        random_df = RandomizedSearchCV(estimator, param_distributions=param_vals,\n",
    "                              n_iter=itr, random_state=256, n_jobs=-1)\n",
    "        random_df.fit(X_train, y_train)\n",
    "        best_model = random_df.best_estimator_\n",
    "        \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0754f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "779029bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = df.loc[:, first_Feature: last_Feature].columns.tolist()\n",
    "label_cols = output_label\n",
    "\n",
    "\n",
    "input_df = df.loc[:, input_cols]\n",
    "\n",
    "numeric_cols = input_df.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = input_df.select_dtypes('object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eec0d8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "5                 0.07613  ...         15.47          23.75           103.40   \n",
       "6                 0.05742  ...         22.88          27.66           153.20   \n",
       "7                 0.07451  ...         17.06          28.14           110.60   \n",
       "8                 0.07389  ...         15.49          30.73           106.20   \n",
       "9                 0.08243  ...         15.09          40.68            97.65   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "5       741.6            0.1791             0.5249           0.5355   \n",
       "6      1606.0            0.1442             0.2576           0.3784   \n",
       "7       897.0            0.1654             0.3682           0.2678   \n",
       "8       739.3            0.1703             0.5401           0.5390   \n",
       "9       711.4            0.1853             1.0580           1.1050   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "5                0.1741          0.3985                  0.12440  \n",
       "6                0.1932          0.3063                  0.08368  \n",
       "7                0.1556          0.3196                  0.11510  \n",
       "8                0.2060          0.4378                  0.10720  \n",
       "9                0.2210          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a676f83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radius_mean',\n",
       " 'texture_mean',\n",
       " 'perimeter_mean',\n",
       " 'area_mean',\n",
       " 'smoothness_mean',\n",
       " 'compactness_mean',\n",
       " 'concavity_mean',\n",
       " 'concave points_mean',\n",
       " 'symmetry_mean',\n",
       " 'fractal_dimension_mean',\n",
       " 'radius_se',\n",
       " 'texture_se',\n",
       " 'perimeter_se',\n",
       " 'area_se',\n",
       " 'smoothness_se',\n",
       " 'compactness_se',\n",
       " 'concavity_se',\n",
       " 'concave points_se',\n",
       " 'symmetry_se',\n",
       " 'fractal_dimension_se',\n",
       " 'radius_worst',\n",
       " 'texture_worst',\n",
       " 'perimeter_worst',\n",
       " 'area_worst',\n",
       " 'smoothness_worst',\n",
       " 'compactness_worst',\n",
       " 'concavity_worst',\n",
       " 'concave points_worst',\n",
       " 'symmetry_worst',\n",
       " 'fractal_dimension_worst']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cb44c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45bfb654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oneHotEncode\n",
      "Impute\n",
      "cutMissingRows\n",
      "Scaling\n",
      "MinMaxScaler\n"
     ]
    }
   ],
   "source": [
    "def data_prep(df, input_cols, label_cols, numeric_cols, categorical_cols, options):\n",
    "    #Preprocess data\n",
    "    df_new, input_cols = preprocess(df, input_cols, label_cols, numeric_cols, categorical_cols, oneHotEncode=options['oneHotEncode'], \n",
    "                    Impute=options['Impute'], cutMissingRows=options['cutMissingRows'],\n",
    "                    removeBig=options['removeBig'], N=options['removeBig_N'],\n",
    "                   Scaling=options['Scaling'], scalingMethod=options['scalingMethod'], \n",
    "                        QuantileTransformer=options['QuantileTransformer'],\n",
    "                        Normalize=options['Normalize'])\n",
    "\n",
    "    #Split data into train/val/test sets\n",
    "    train_val_df, test_df = train_test_split(df_new, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #Seperate the inputs and outputs for training data\n",
    "    input_df_train, output_df_train = split(train_val_df, input_cols, label_cols)\n",
    "    \n",
    "    #Seperate the inputs and outputs for test data\n",
    "    input_df_test, output_df_test = split(test_df, input_cols, label_cols)\n",
    "    \n",
    "    return input_df_train, output_df_train, input_df_test, output_df_test\n",
    "    \n",
    "input_df_train, output_df_train, input_df_test, output_df_test  = data_prep(df, input_cols, label_cols, numeric_cols, categorical_cols, options)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f376aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.096928</td>\n",
       "      <td>0.257694</td>\n",
       "      <td>0.103656</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.487226</td>\n",
       "      <td>0.373965</td>\n",
       "      <td>0.733365</td>\n",
       "      <td>0.217445</td>\n",
       "      <td>0.530808</td>\n",
       "      <td>0.642376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084667</td>\n",
       "      <td>0.283316</td>\n",
       "      <td>0.075153</td>\n",
       "      <td>0.034285</td>\n",
       "      <td>0.508684</td>\n",
       "      <td>0.397018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601375</td>\n",
       "      <td>0.524936</td>\n",
       "      <td>0.409681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.667755</td>\n",
       "      <td>0.570172</td>\n",
       "      <td>0.683505</td>\n",
       "      <td>0.495228</td>\n",
       "      <td>0.554934</td>\n",
       "      <td>0.809214</td>\n",
       "      <td>0.582709</td>\n",
       "      <td>0.743539</td>\n",
       "      <td>0.674242</td>\n",
       "      <td>0.505897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667022</td>\n",
       "      <td>0.571962</td>\n",
       "      <td>0.627970</td>\n",
       "      <td>0.467902</td>\n",
       "      <td>0.514627</td>\n",
       "      <td>0.709327</td>\n",
       "      <td>0.541534</td>\n",
       "      <td>0.997595</td>\n",
       "      <td>0.499310</td>\n",
       "      <td>0.481175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.103744</td>\n",
       "      <td>0.140345</td>\n",
       "      <td>0.106489</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.221901</td>\n",
       "      <td>0.208975</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.108350</td>\n",
       "      <td>0.646970</td>\n",
       "      <td>0.414280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073995</td>\n",
       "      <td>0.192164</td>\n",
       "      <td>0.075601</td>\n",
       "      <td>0.030697</td>\n",
       "      <td>0.179555</td>\n",
       "      <td>0.136324</td>\n",
       "      <td>0.111581</td>\n",
       "      <td>0.174811</td>\n",
       "      <td>0.338459</td>\n",
       "      <td>0.195855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.173648</td>\n",
       "      <td>0.524518</td>\n",
       "      <td>0.167369</td>\n",
       "      <td>0.086320</td>\n",
       "      <td>0.396678</td>\n",
       "      <td>0.162444</td>\n",
       "      <td>0.055740</td>\n",
       "      <td>0.080268</td>\n",
       "      <td>0.422727</td>\n",
       "      <td>0.280750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153682</td>\n",
       "      <td>0.617537</td>\n",
       "      <td>0.137308</td>\n",
       "      <td>0.066482</td>\n",
       "      <td>0.519910</td>\n",
       "      <td>0.109158</td>\n",
       "      <td>0.089856</td>\n",
       "      <td>0.210859</td>\n",
       "      <td>0.363493</td>\n",
       "      <td>0.173357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.150930</td>\n",
       "      <td>0.174839</td>\n",
       "      <td>0.143459</td>\n",
       "      <td>0.071432</td>\n",
       "      <td>0.548614</td>\n",
       "      <td>0.187811</td>\n",
       "      <td>0.025398</td>\n",
       "      <td>0.064115</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.413648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109925</td>\n",
       "      <td>0.144723</td>\n",
       "      <td>0.096867</td>\n",
       "      <td>0.045075</td>\n",
       "      <td>0.371987</td>\n",
       "      <td>0.069244</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>0.088625</td>\n",
       "      <td>0.392667</td>\n",
       "      <td>0.165027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.357755</td>\n",
       "      <td>0.602976</td>\n",
       "      <td>0.365835</td>\n",
       "      <td>0.218579</td>\n",
       "      <td>0.553128</td>\n",
       "      <td>0.429790</td>\n",
       "      <td>0.384021</td>\n",
       "      <td>0.366004</td>\n",
       "      <td>0.627778</td>\n",
       "      <td>0.438290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339025</td>\n",
       "      <td>0.669243</td>\n",
       "      <td>0.367000</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.638117</td>\n",
       "      <td>0.611627</td>\n",
       "      <td>0.561182</td>\n",
       "      <td>0.588316</td>\n",
       "      <td>0.522965</td>\n",
       "      <td>0.518562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.351602</td>\n",
       "      <td>0.338857</td>\n",
       "      <td>0.360998</td>\n",
       "      <td>0.215270</td>\n",
       "      <td>0.315428</td>\n",
       "      <td>0.454635</td>\n",
       "      <td>0.319119</td>\n",
       "      <td>0.328131</td>\n",
       "      <td>0.330303</td>\n",
       "      <td>0.462511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278904</td>\n",
       "      <td>0.269456</td>\n",
       "      <td>0.255441</td>\n",
       "      <td>0.143064</td>\n",
       "      <td>0.189262</td>\n",
       "      <td>0.213358</td>\n",
       "      <td>0.177316</td>\n",
       "      <td>0.350859</td>\n",
       "      <td>0.139365</td>\n",
       "      <td>0.216122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.210564</td>\n",
       "      <td>0.192087</td>\n",
       "      <td>0.202267</td>\n",
       "      <td>0.108717</td>\n",
       "      <td>0.395053</td>\n",
       "      <td>0.151862</td>\n",
       "      <td>0.082076</td>\n",
       "      <td>0.142893</td>\n",
       "      <td>0.340404</td>\n",
       "      <td>0.183024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156172</td>\n",
       "      <td>0.266525</td>\n",
       "      <td>0.147019</td>\n",
       "      <td>0.068030</td>\n",
       "      <td>0.315856</td>\n",
       "      <td>0.133413</td>\n",
       "      <td>0.111741</td>\n",
       "      <td>0.291271</td>\n",
       "      <td>0.219003</td>\n",
       "      <td>0.082710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.249373</td>\n",
       "      <td>0.278323</td>\n",
       "      <td>0.238270</td>\n",
       "      <td>0.134380</td>\n",
       "      <td>0.306130</td>\n",
       "      <td>0.145421</td>\n",
       "      <td>0.091026</td>\n",
       "      <td>0.115855</td>\n",
       "      <td>0.459596</td>\n",
       "      <td>0.259478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201352</td>\n",
       "      <td>0.351812</td>\n",
       "      <td>0.180238</td>\n",
       "      <td>0.093148</td>\n",
       "      <td>0.333686</td>\n",
       "      <td>0.146996</td>\n",
       "      <td>0.155192</td>\n",
       "      <td>0.282165</td>\n",
       "      <td>0.305145</td>\n",
       "      <td>0.172373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.610961</td>\n",
       "      <td>0.356781</td>\n",
       "      <td>0.599198</td>\n",
       "      <td>0.454083</td>\n",
       "      <td>0.461045</td>\n",
       "      <td>0.342372</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.468738</td>\n",
       "      <td>0.374747</td>\n",
       "      <td>0.251053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562078</td>\n",
       "      <td>0.352079</td>\n",
       "      <td>0.548284</td>\n",
       "      <td>0.359025</td>\n",
       "      <td>0.465760</td>\n",
       "      <td>0.294564</td>\n",
       "      <td>0.334265</td>\n",
       "      <td>0.554296</td>\n",
       "      <td>0.193968</td>\n",
       "      <td>0.238226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "68      0.096928      0.257694        0.103656   0.045387         0.487226   \n",
       "181     0.667755      0.570172        0.683505   0.495228         0.554934   \n",
       "63      0.103744      0.140345        0.106489   0.049799         0.221901   \n",
       "248     0.173648      0.524518        0.167369   0.086320         0.396678   \n",
       "60      0.150930      0.174839        0.143459   0.071432         0.548614   \n",
       "15      0.357755      0.602976        0.365835   0.218579         0.553128   \n",
       "290     0.351602      0.338857        0.360998   0.215270         0.315428   \n",
       "137     0.210564      0.192087        0.202267   0.108717         0.395053   \n",
       "155     0.249373      0.278323        0.238270   0.134380         0.306130   \n",
       "517     0.610961      0.356781        0.599198   0.454083         0.461045   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "68           0.373965        0.733365             0.217445       0.530808   \n",
       "181          0.809214        0.582709             0.743539       0.674242   \n",
       "63           0.208975        0.140300             0.108350       0.646970   \n",
       "248          0.162444        0.055740             0.080268       0.422727   \n",
       "60           0.187811        0.025398             0.064115       0.850000   \n",
       "15           0.429790        0.384021             0.366004       0.627778   \n",
       "290          0.454635        0.319119             0.328131       0.330303   \n",
       "137          0.151862        0.082076             0.142893       0.340404   \n",
       "155          0.145421        0.091026             0.115855       0.459596   \n",
       "517          0.342372        0.330600             0.468738       0.374747   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "68                 0.642376  ...      0.084667       0.283316   \n",
       "181                0.505897  ...      0.667022       0.571962   \n",
       "63                 0.414280  ...      0.073995       0.192164   \n",
       "248                0.280750  ...      0.153682       0.617537   \n",
       "60                 0.413648  ...      0.109925       0.144723   \n",
       "15                 0.438290  ...      0.339025       0.669243   \n",
       "290                0.462511  ...      0.278904       0.269456   \n",
       "137                0.183024  ...      0.156172       0.266525   \n",
       "155                0.259478  ...      0.201352       0.351812   \n",
       "517                0.251053  ...      0.562078       0.352079   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "68          0.075153    0.034285          0.508684           0.397018   \n",
       "181         0.627970    0.467902          0.514627           0.709327   \n",
       "63          0.075601    0.030697          0.179555           0.136324   \n",
       "248         0.137308    0.066482          0.519910           0.109158   \n",
       "60          0.096867    0.045075          0.371987           0.069244   \n",
       "15          0.367000    0.186296          0.638117           0.611627   \n",
       "290         0.255441    0.143064          0.189262           0.213358   \n",
       "137         0.147019    0.068030          0.315856           0.133413   \n",
       "155         0.180238    0.093148          0.333686           0.146996   \n",
       "517         0.548284    0.359025          0.465760           0.294564   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "68          1.000000              0.601375        0.524936   \n",
       "181         0.541534              0.997595        0.499310   \n",
       "63          0.111581              0.174811        0.338459   \n",
       "248         0.089856              0.210859        0.363493   \n",
       "60          0.017316              0.088625        0.392667   \n",
       "15          0.561182              0.588316        0.522965   \n",
       "290         0.177316              0.350859        0.139365   \n",
       "137         0.111741              0.291271        0.219003   \n",
       "155         0.155192              0.282165        0.305145   \n",
       "517         0.334265              0.554296        0.193968   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "68                  0.409681  \n",
       "181                 0.481175  \n",
       "63                  0.195855  \n",
       "248                 0.173357  \n",
       "60                  0.165027  \n",
       "15                  0.518562  \n",
       "290                 0.216122  \n",
       "137                 0.082710  \n",
       "155                 0.172373  \n",
       "517                 0.238226  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "728a84c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68     B\n",
       "181    M\n",
       "63     B\n",
       "248    B\n",
       "60     B\n",
       "15     M\n",
       "290    B\n",
       "137    B\n",
       "155    B\n",
       "517    M\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95ae48c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204    B\n",
       "70     M\n",
       "131    M\n",
       "431    B\n",
       "540    B\n",
       "567    M\n",
       "369    M\n",
       "29     M\n",
       "81     B\n",
       "477    B\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0f404c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(input_df_train, output_df_train, input_df_test, output_df_test, options, algorithms, _scoring):\n",
    "    for algorithm in algorithms:\n",
    "        filename = algorithm + \".txt\"\n",
    "        f = open(filename, \"w\")\n",
    "        print(\"_____________________________________________________________________________________________________\")\n",
    "        print(\"Algorithm:\", algorithm)\n",
    "        print(\"Label:\", output_df_train.name)\n",
    "        f.write(\"_____________________________________________________________________________________________________\")\n",
    "        f.write(\"\\nAlgorithm: %s\"% algorithm)\n",
    "        f.write(\"\\nLabel: %s\"% output_df_train.name)\n",
    "        if options['rebalance'] == True:\n",
    "            input_df_train_reb, output_df_train_reb = rebalance(input_df_train, output_df_train, options['rebalance_type'])\n",
    "        else:\n",
    "            input_df_train_reb = input_df_train.copy()\n",
    "            output_df_train_reb = output_df_train.copy()\n",
    "        if options['FeatureSelection'] == True:\n",
    "            input_df_train_fs, selected_features = feature_selection(input_df_train_reb, output_df_train_reb, method=options['method'], type=options['type'], N=options['N_features'], per=options['per'])\n",
    "            print(selected_features)\n",
    "            f.write(\"\\nSelected Features: %s\"%selected_features)\n",
    "        else:\n",
    "            input_df_train_fs = input_df_train_reb.copy()\n",
    "            selected_features = list(input_df_train_reb.columns)\n",
    "        estimator, param_vals = get_classifier(algorithm)\n",
    "        best_model = train_tune(estimator, param_vals, input_df_train_fs, output_df_train_reb, options['strategy'], itr=options['itr'])\n",
    "        params = best_model.get_params()\n",
    "        f.write(\"\\nParameters: %s\"%params)\n",
    "        predictions_test = best_model.predict(input_df_test[selected_features])\n",
    "        probas_test = best_model.predict_proba(input_df_test[selected_features])\n",
    "        #print(probas_test)\n",
    "        acc_score = accuracy_score(output_df_test, predictions_test)\n",
    "        class_report = classification_report(output_df_test, predictions_test)\n",
    "        f.write(\"\\n Test Acuracy Score: %s\"%acc_score)\n",
    "        print(\"Test Acuracy Score:\", acc_score)\n",
    "        f.write(\"\\n Classification Report: \\n%s\"%class_report)\n",
    "        print(class_report)\n",
    "        filename_prob = algorithm + \"_\" + output_df_test.name + \"_prob.joblib\"\n",
    "        filename_pred = algorithm + \"_\" + output_df_test.name + \"_pred.joblib\"\n",
    "        joblib.dump(probas_test, filename_prob)\n",
    "        joblib.dump(predictions_test, filename_pred)\n",
    "        modelname = algorithm + \"_\" + output_df_test.name + \"_model.joblib\"\n",
    "        joblib.dump(best_model, modelname)\n",
    "        f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d55f0eae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________________________________________________________________\n",
      "Algorithm: rf\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.97      0.97        71\n",
      "           M       0.95      0.93      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "_____________________________________________________________________________________________________\n",
      "Algorithm: AdaBoost\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.97      0.97        71\n",
      "           M       0.95      0.93      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "_____________________________________________________________________________________________________\n",
      "Algorithm: sgd_elastic\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      0.97      0.97        71\n",
      "           M       0.95      0.95      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "_____________________________________________________________________________________________________\n",
      "Algorithm: sgd_l2\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.99      0.97      0.98        71\n",
      "           M       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "_____________________________________________________________________________________________________\n",
      "Algorithm: lr_l2\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 23.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      0.99      0.97        71\n",
      "           M       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "_____________________________________________________________________________________________________\n",
      "Algorithm: lr\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      0.99      0.97        71\n",
      "           M       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "_____________________________________________________________________________________________________\n",
      "Algorithm: dt\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 26.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.9298245614035088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.92      0.97      0.95        71\n",
      "           M       0.95      0.86      0.90        43\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "_____________________________________________________________________________________________________\n",
      "Algorithm: GaussianNB\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      1.00      0.98        71\n",
      "           M       1.00      0.93      0.96        43\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "_____________________________________________________________________________________________________\n",
      "Algorithm: svm\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.956140350877193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      0.99      0.97        71\n",
      "           M       0.97      0.91      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "_____________________________________________________________________________________________________\n",
      "Algorithm: knn\n",
      "Label: diagnosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concave points_worst', 'perimeter_worst', 'concave points_mean', 'radius_worst', 'perimeter_mean', 'area_worst', 'radius_mean', 'concavity_mean', 'concavity_worst', 'area_mean']\n",
      "Test Acuracy Score: 0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.99      0.97        71\n",
      "           M       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(input_df_train, output_df_train, input_df_test, output_df_test, options, algorithms, _scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba85b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b97df34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ded1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6538ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
